{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# Infant Respiration Estimation - Google Colab Pipeline\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/J0R0W/Infant-Respiration-Estimation/blob/main/AIR_Complete_Pipeline_Colab.ipynb)\n",
    "\n",
    "Dieses Notebook enth√§lt alle erforderlichen Schritte zum Ausf√ºhren des Infant Respiration Estimation Projekts **in Google Colab**.\n",
    "\n",
    "## √úberblick\n",
    "\n",
    "Dieses Projekt implementiert automatische Atmungssch√§tzung bei S√§uglingen aus Videos unter Verwendung von Deep Learning-Methoden, insbesondere dem **AIRFlowNet**-Modell.\n",
    "\n",
    "**Paper:** [Automatic Infant Respiration Estimation from Video: A Deep Flow-based Algorithm and a Novel Public Benchmark](https://arxiv.org/pdf/2307.13110.pdf)\n",
    "\n",
    "### Unterst√ºtzte Modelle:\n",
    "- **VIRENet** (AIRFlowNet)\n",
    "- DeepPhys\n",
    "- EfficientPhys\n",
    "- TS-CAN\n",
    "\n",
    "### Datasets:\n",
    "- **AIR-125**: 125 annotierte S√§uglingsvideos\n",
    "- **COHFACE**: Erwachsenen-Atmungsdatensatz\n",
    "\n",
    "---\n",
    "\n",
    "## Wichtige Hinweise f√ºr Google Colab:\n",
    "\n",
    "1. **GPU Runtime**: Stelle sicher, dass du eine GPU-Runtime verwendest\n",
    "   - `Runtime` ‚Üí `Change runtime type` ‚Üí `Hardware accelerator: GPU` (T4 empfohlen)\n",
    "\n",
    "2. **Session-Dauer**: Colab-Sessions haben eine Zeitbegrenzung. Speichere wichtige Ergebnisse regelm√§√üig.\n",
    "\n",
    "3. **Google Drive**: Optional kannst du Google Drive mounten, um Daten zu persistieren.\n",
    "\n",
    "4. **Erster Durchlauf**: Der erste Durchlauf dauert l√§nger wegen Repository-Klon und Dataset-Download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "check-gpu"
   },
   "source": [
    "## 1. GPU-√úberpr√ºfung\n",
    "\n",
    "√úberpr√ºfe, ob eine GPU verf√ºgbar ist. Falls nicht, √§ndere die Runtime-Einstellungen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu-code"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"Current Working Directory: {os.getcwd()}\")\n",
    "\n",
    "# Pr√ºfe GPU-Verf√ºgbarkeit\n",
    "!nvidia-smi\n",
    "\n",
    "# Pr√ºfe CUDA mit PyTorch (falls bereits installiert)\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"\\nPyTorch Version: {torch.__version__}\")\n",
    "    print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "except ImportError:\n",
    "    print(\"\\nPyTorch wird in einem sp√§teren Schritt installiert.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"‚úì GPU ist verf√ºgbar! Training wird schneller sein.\")\n",
    "else:\n",
    "    print(\"‚ö† WARNUNG: Keine GPU verf√ºgbar!\")\n",
    "    print(\"  Bitte √§ndere die Runtime: Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mount-drive"
   },
   "source": [
    "## 2. Google Drive mounten (Optional)\n",
    "\n",
    "Du kannst Google Drive mounten, um Datasets, Modelle und Ergebnisse zu persistieren.\n",
    "\n",
    "**Vorteile:**\n",
    "- Daten bleiben nach Session-Ende erhalten\n",
    "- Schnellerer Zugriff bei wiederholten Ausf√ºhrungen\n",
    "- Teilen von Daten zwischen verschiedenen Notebooks\n",
    "\n",
    "**Optional:** √úberspringe diesen Schritt, wenn du Drive nicht verwenden m√∂chtest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount-drive-code"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Uncomment die n√§chste Zeile, um Google Drive zu mounten\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Optional: Erstelle ein Projektverzeichnis in Drive\n",
    "# project_dir = '/content/drive/MyDrive/InfantRespiration'\n",
    "# os.makedirs(project_dir, exist_ok=True)\n",
    "# print(f\"Projektverzeichnis: {project_dir}\")\n",
    "\n",
    "print(\"Google Drive Mount √ºbersprungen.\")\n",
    "print(\"Alle Daten werden im tempor√§ren Colab-Speicher abgelegt.\")\n",
    "print(\"\\nHinweis: Daten gehen verloren, wenn die Runtime beendet wird.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clone-repo"
   },
   "source": [
    "## 3. Repository klonen\n",
    "\n",
    "Klone das Infant Respiration Estimation Repository von GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone-repo-code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Repository URL\n",
    "repo_url = \"https://github.com/J0R0W/Infant-Respiration-Estimation.git\"\n",
    "repo_name = \"Infant-Respiration-Estimation\"\n",
    "repo_path = Path(f\"/content/{repo_name}\")\n",
    "\n",
    "# Klone das Repository, falls es noch nicht existiert\n",
    "if not repo_path.exists():\n",
    "    print(f\"Klone Repository von {repo_url}...\")\n",
    "    !git clone {repo_url} {repo_path}\n",
    "    print(f\"\\n‚úì Repository geklont: {repo_path}\")\n",
    "else:\n",
    "    print(f\"Repository existiert bereits: {repo_path}\")\n",
    "    print(\"Aktualisiere Repository...\")\n",
    "    !cd {repo_path} && git pull\n",
    "\n",
    "# Wechsle ins Repository-Verzeichnis\n",
    "os.chdir(repo_path)\n",
    "print(f\"\\nCurrent Working Directory: {os.getcwd()}\")\n",
    "\n",
    "# Zeige Repository-Struktur\n",
    "print(\"\\nRepository-Struktur:\")\n",
    "!ls -la\n",
    "\n",
    "# F√ºge Repository zum Python-Path hinzu\n",
    "if str(repo_path) not in sys.path:\n",
    "    sys.path.insert(0, str(repo_path))\n",
    "    print(f\"\\n‚úì {repo_path} zum Python-Path hinzugef√ºgt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install-deps"
   },
   "source": [
    "## 4. Installation der Abh√§ngigkeiten\n",
    "\n",
    "Installiere alle erforderlichen Python-Pakete.\n",
    "\n",
    "**Hinweis:** Dieser Schritt kann 5-10 Minuten dauern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps-code"
   },
   "outputs": [],
   "source": [
    "# Installiere PyTorch zuerst (falls nicht bereits vorhanden)\n",
    "print(\"√úberpr√ºfe PyTorch-Installation...\")\n",
    "!pip install -q torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "\n",
    "# Installiere requirements aus der requirements.txt\n",
    "print(\"\\nInstalliere Projekt-Abh√§ngigkeiten...\")\n",
    "!pip install -q -r requirements.txt\n",
    "\n",
    "# Zus√§tzliche Pakete f√ºr Notebook-Visualisierung\n",
    "!pip install -q ipywidgets\n",
    "\n",
    "print(\"\\n‚úì Alle Abh√§ngigkeiten installiert!\")\n",
    "\n",
    "# Verifiziere die Installation\n",
    "print(\"\\nVerifiziere Installation...\")\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(f\"‚úì PyTorch {torch.__version__}\")\n",
    "print(f\"‚úì NumPy {np.__version__}\")\n",
    "print(f\"‚úì OpenCV {cv2.__version__}\")\n",
    "print(f\"‚úì CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download-dataset"
   },
   "source": [
    "## 5. Dataset Download und Extraktion\n",
    "\n",
    "Lade den AIR-125 Dataset herunter und extrahiere ihn.\n",
    "\n",
    "**Hinweis:** \n",
    "- Dataset-Gr√∂√üe: ~mehrere GB\n",
    "- Download kann 10-30 Minuten dauern, je nach Verbindung\n",
    "- Falls Google Drive gemountet ist, kannst du den Pfad anpassen, um den Dataset dort zu speichern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download-dataset-code"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Definiere Pfade\n",
    "# Option 1: In Colab-Speicher (tempor√§r)\n",
    "dataset_url = \"https://coe.northeastern.edu/Research/AClab/AIR-125/AIR.zip\"\n",
    "download_path = Path(\"/content/data/AIR.zip\")\n",
    "extract_path = Path(\"/content/data/AIR\")\n",
    "\n",
    "# Option 2: In Google Drive (persistent) - uncomment falls Drive gemountet\n",
    "# download_path = Path(\"/content/drive/MyDrive/InfantRespiration/data/AIR.zip\")\n",
    "# extract_path = Path(\"/content/drive/MyDrive/InfantRespiration/data/AIR\")\n",
    "\n",
    "# Erstelle Verzeichnis\n",
    "download_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Download mit Fortschrittsanzeige\n",
    "class DownloadProgressBar(tqdm):\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "if not download_path.exists():\n",
    "    print(f\"Downloading AIR-125 dataset from {dataset_url}...\")\n",
    "    print(\"Dies kann 10-30 Minuten dauern, je nach Internetgeschwindigkeit.\")\n",
    "    print(\"‚òï Zeit f√ºr einen Kaffee!\\n\")\n",
    "    \n",
    "    with DownloadProgressBar(unit='B', unit_scale=True, miniters=1, desc='AIR.zip') as t:\n",
    "        urllib.request.urlretrieve(dataset_url, download_path, reporthook=t.update_to)\n",
    "    print(f\"\\n‚úì Download abgeschlossen: {download_path}\")\n",
    "else:\n",
    "    print(f\"‚úì Dataset bereits heruntergeladen: {download_path}\")\n",
    "    print(f\"  Gr√∂√üe: {download_path.stat().st_size / 1e9:.2f} GB\")\n",
    "\n",
    "# Extrahiere ZIP-Datei\n",
    "if not extract_path.exists():\n",
    "    print(f\"\\nExtrahiere Dataset nach {extract_path}...\")\n",
    "    print(\"Dies kann einige Minuten dauern...\")\n",
    "    with zipfile.ZipFile(download_path, 'r') as zip_ref:\n",
    "        # Extrahiere mit Fortschrittsanzeige\n",
    "        members = zip_ref.namelist()\n",
    "        for member in tqdm(members, desc='Extracting'):\n",
    "            zip_ref.extract(member, extract_path.parent)\n",
    "    print(\"‚úì Extraktion abgeschlossen!\")\n",
    "else:\n",
    "    print(f\"‚úì Dataset bereits extrahiert: {extract_path}\")\n",
    "\n",
    "# Zeige Dataset-Struktur\n",
    "print(\"\\nDataset-Struktur:\")\n",
    "!du -sh {extract_path}\n",
    "print(\"\\nInhalt:\")\n",
    "!ls -lh {extract_path} | head -15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inspect-dataset"
   },
   "source": [
    "## 6. Dataset-Inspektion\n",
    "\n",
    "Schaue dir die Dataset-Struktur und einige Sample-Daten an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inspect-dataset-code"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Verwende den gleichen Pfad wie beim Download\n",
    "dataset_path = Path(\"/content/data/AIR\")\n",
    "# dataset_path = Path(\"/content/drive/MyDrive/InfantRespiration/data/AIR\")  # Falls Drive verwendet\n",
    "\n",
    "if dataset_path.exists():\n",
    "    # Z√§hle Dateien\n",
    "    video_files = list(dataset_path.rglob('*.avi')) + list(dataset_path.rglob('*.mp4'))\n",
    "    mat_files = list(dataset_path.rglob('*.mat'))\n",
    "    \n",
    "    print(f\"Dataset-Statistiken:\")\n",
    "    print(f\"  Anzahl Video-Dateien: {len(video_files)}\")\n",
    "    print(f\"  Anzahl MAT-Dateien (Annotationen): {len(mat_files)}\")\n",
    "    \n",
    "    if video_files:\n",
    "        print(\"\\nBeispiel Video-Dateien:\")\n",
    "        for vf in video_files[:5]:\n",
    "            file_size = vf.stat().st_size / 1e6\n",
    "            print(f\"  - {vf.name} ({file_size:.1f} MB)\")\n",
    "        \n",
    "        # Lade ein Sample-Video\n",
    "        sample_video = video_files[0]\n",
    "        print(f\"\\nLade Sample-Video: {sample_video.name}\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(str(sample_video))\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            # Zeige mehrere Frames\n",
    "            frames_to_show = 4\n",
    "            fig, axes = plt.subplots(1, frames_to_show, figsize=(20, 5))\n",
    "            \n",
    "            frame_indices = np.linspace(0, int(cap.get(cv2.CAP_PROP_FRAME_COUNT))-1, frames_to_show, dtype=int)\n",
    "            \n",
    "            for idx, frame_idx in enumerate(frame_indices):\n",
    "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "                ret, frame = cap.read()\n",
    "                if ret:\n",
    "                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                    axes[idx].imshow(frame_rgb)\n",
    "                    axes[idx].set_title(f\"Frame {frame_idx}\")\n",
    "                    axes[idx].axis('off')\n",
    "            \n",
    "            plt.suptitle(f\"Sample Frames from {sample_video.name}\", fontsize=14)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Video-Informationen\n",
    "            fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "            width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "            height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "            duration = frame_count / fps if fps > 0 else 0\n",
    "            \n",
    "            print(f\"\\nVideo-Informationen:\")\n",
    "            print(f\"  FPS: {fps:.2f}\")\n",
    "            print(f\"  Frames: {frame_count}\")\n",
    "            print(f\"  Aufl√∂sung: {width}x{height}\")\n",
    "            print(f\"  Dauer: {duration:.2f} Sekunden\")\n",
    "        \n",
    "        cap.release()\n",
    "    else:\n",
    "        print(\"\\n‚ö† Keine Video-Dateien gefunden!\")\n",
    "else:\n",
    "    print(f\"‚ö† Dataset-Pfad nicht gefunden: {dataset_path}\")\n",
    "    print(\"Bitte f√ºhre Zelle 5 aus, um das Dataset herunterzuladen.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create-config"
   },
   "source": [
    "## 7. Konfiguration erstellen\n",
    "\n",
    "Erstelle eine Konfigurationsdatei f√ºr das Training mit dem AIR-125 Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-config-code"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Stelle sicher, dass wir im Repository-Verzeichnis sind\n",
    "repo_path = Path(\"/content/Infant-Respiration-Estimation\")\n",
    "os.chdir(repo_path)\n",
    "\n",
    "# Definiere Pfade (verwende die gleichen wie beim Download)\n",
    "raw_data_path = \"/content/data/AIR\"\n",
    "processed_data_path = \"/content/data/processed_AIR\"\n",
    "\n",
    "# Falls Google Drive verwendet wird, uncomment:\n",
    "# raw_data_path = \"/content/drive/MyDrive/InfantRespiration/data/AIR\"\n",
    "# processed_data_path = \"/content/drive/MyDrive/InfantRespiration/data/processed_AIR\"\n",
    "\n",
    "# Erstelle processed data Verzeichnis\n",
    "Path(processed_data_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Erstelle Konfiguration f√ºr VIRENet\n",
    "config = {\n",
    "    'BASE': [''],\n",
    "    'TOOLBOX_MODE': 'train_and_test',\n",
    "    'TRAIN': {\n",
    "        'BATCH_SIZE': 4,\n",
    "        'EPOCHS': 10,\n",
    "        'LR': 0.001,\n",
    "        'MODEL_FILE_NAME': 'AIR_VIRENet_Colab',\n",
    "        'DATA': {\n",
    "            'FS': 5,\n",
    "            'DATASET': 'AIR',\n",
    "            'DO_PREPROCESS': True,\n",
    "            'DATA_FORMAT': 'NDCHW',\n",
    "            'DATA_PATH': raw_data_path,\n",
    "            'CACHED_PATH': processed_data_path,\n",
    "            'EXP_DATA_NAME': '',\n",
    "            'BEGIN': 0.0,\n",
    "            'END': 0.7,\n",
    "            'PREPROCESS': {\n",
    "                'DATA_TYPE': ['Standardized'],\n",
    "                'LABEL_TYPE': 'Standardized',\n",
    "                'DO_CHUNK': True,\n",
    "                'CHUNK_LENGTH': 60,\n",
    "                'DYNAMIC_DETECTION': False,\n",
    "                'DYNAMIC_DETECTION_FREQUENCY': 60,\n",
    "                'CROP_FACE': False,\n",
    "                'LARGE_FACE_BOX': True,\n",
    "                'LARGE_BOX_COEF': 1.5,\n",
    "                'H': 96,\n",
    "                'W': 96\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'VALID': {\n",
    "        'DATA': {\n",
    "            'FS': 5,\n",
    "            'DATASET': 'AIR',\n",
    "            'DO_PREPROCESS': True,\n",
    "            'DATA_FORMAT': 'NDCHW',\n",
    "            'DATA_PATH': raw_data_path,\n",
    "            'CACHED_PATH': processed_data_path,\n",
    "            'EXP_DATA_NAME': '',\n",
    "            'BEGIN': 0.7,\n",
    "            'END': 1.0,\n",
    "            'PREPROCESS': {\n",
    "                'DATA_TYPE': ['Standardized'],\n",
    "                'LABEL_TYPE': 'Standardized',\n",
    "                'DO_CHUNK': True,\n",
    "                'CHUNK_LENGTH': 60,\n",
    "                'DYNAMIC_DETECTION': False,\n",
    "                'DYNAMIC_DETECTION_FREQUENCY': 60,\n",
    "                'CROP_FACE': False,\n",
    "                'LARGE_FACE_BOX': True,\n",
    "                'LARGE_BOX_COEF': 1.5,\n",
    "                'H': 96,\n",
    "                'W': 96\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'TEST': {\n",
    "        'METRICS': ['MAE', 'RMSE', 'MAPE', 'Pearson'],\n",
    "        'USE_LAST_EPOCH': False,\n",
    "        'DATA': {\n",
    "            'FS': 5,\n",
    "            'DATASET': 'AIR',\n",
    "            'DO_PREPROCESS': True,\n",
    "            'DATA_FORMAT': 'NDCHW',\n",
    "            'DATA_PATH': raw_data_path,\n",
    "            'CACHED_PATH': processed_data_path,\n",
    "            'EXP_DATA_NAME': '',\n",
    "            'BEGIN': 0.0,\n",
    "            'END': 1.0,\n",
    "            'PREPROCESS': {\n",
    "                'DATA_TYPE': ['Standardized'],\n",
    "                'LABEL_TYPE': 'Standardized',\n",
    "                'DO_CHUNK': True,\n",
    "                'CHUNK_LENGTH': 60,\n",
    "                'DYNAMIC_DETECTION': False,\n",
    "                'DYNAMIC_DETECTION_FREQUENCY': 60,\n",
    "                'CROP_FACE': False,\n",
    "                'LARGE_FACE_BOX': True,\n",
    "                'LARGE_BOX_COEF': 1.5,\n",
    "                'H': 96,\n",
    "                'W': 96\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    'DEVICE': 'cuda:0',\n",
    "    'NUM_OF_GPU_TRAIN': 1,\n",
    "    'LOG': {\n",
    "        'PATH': 'runs/exp'\n",
    "    },\n",
    "    'MODEL': {\n",
    "        'DROP_RATE': 0.2,\n",
    "        'NAME': 'VIRENet',\n",
    "        'MODEL_DIR': '',\n",
    "        'VIRENET': {\n",
    "            'FRAME_DEPTH': 10\n",
    "        }\n",
    "    },\n",
    "    'INFERENCE': {\n",
    "        'BATCH_SIZE': 4,\n",
    "        'EVALUATION_METHOD': 'FFT',\n",
    "        'MODEL_PATH': ''\n",
    "    }\n",
    "}\n",
    "\n",
    "# Speichere Konfiguration\n",
    "config_path = repo_path / 'colab_config.yaml'\n",
    "with open(config_path, 'w') as f:\n",
    "    yaml.dump(config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"‚úì Konfiguration erstellt: {config_path}\")\n",
    "print(f\"\\nDataset-Pfad: {raw_data_path}\")\n",
    "print(f\"Verarbeiteter Dataset-Pfad: {processed_data_path}\")\n",
    "print(f\"\\nKonfiguration:\")\n",
    "print(f\"  Modell: {config['MODEL']['NAME']}\")\n",
    "print(f\"  Batch Size: {config['TRAIN']['BATCH_SIZE']}\")\n",
    "print(f\"  Epochen: {config['TRAIN']['EPOCHS']}\")\n",
    "print(f\"  Learning Rate: {config['TRAIN']['LR']}\")\n",
    "print(f\"  Device: {config['DEVICE']}\")\n",
    "print(f\"\\nWorking Directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train-model"
   },
   "source": [
    "## 8. Model Training\n",
    "\n",
    "Trainiere das VIRENet (AIRFlowNet) Modell auf dem AIR-125 Dataset.\n",
    "\n",
    "**Wichtige Hinweise:**\n",
    "- **Erster Run**: Preprocessing wird durchgef√ºhrt (kann 1-2 Stunden dauern)\n",
    "- **Training**: 10 Epochen k√∂nnen 2-4 Stunden dauern (je nach GPU)\n",
    "- **GPU-Empfehlung**: T4 oder besser\n",
    "- **Session-Timeout**: Colab-Sessions k√∂nnen nach 12 Stunden oder bei Inaktivit√§t unterbrochen werden\n",
    "- **Tipp**: Speichere Zwischenergebnisse in Google Drive f√ºr Persistenz\n",
    "\n",
    "### Training-Fortschritt √ºberwachen:\n",
    "- Loss-Werte sollten sinken\n",
    "- Validierungs-Metriken werden nach jeder Epoche angezeigt\n",
    "- Checkpoints werden automatisch gespeichert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "train-model-code"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Stelle sicher, dass wir im Repository-Verzeichnis sind\n",
    "repo_path = Path(\"/content/Infant-Respiration-Estimation\")\n",
    "os.chdir(repo_path)\n",
    "\n",
    "print(f\"Working Directory: {os.getcwd()}\")\n",
    "print(f\"Config File: {repo_path / 'colab_config.yaml'}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTE TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nDies kann mehrere Stunden dauern...\")\n",
    "print(\"‚òï Zeit f√ºr Pausen!\\n\")\n",
    "\n",
    "# F√ºhre Training aus\n",
    "!python main.py --config_file ./colab_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "test-model"
   },
   "source": [
    "## 9. Model Testing / Inference\n",
    "\n",
    "Nach dem Training evaluieren wir das Modell auf den Testdaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "test-model-code"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "repo_path = Path(\"/content/Infant-Respiration-Estimation\")\n",
    "os.chdir(repo_path)\n",
    "\n",
    "# Lade bestehende Konfiguration\n",
    "with open('colab_config.yaml', 'r') as f:\n",
    "    test_config = yaml.safe_load(f)\n",
    "\n",
    "# √Ñndere Modus auf \"only_test\"\n",
    "test_config['TOOLBOX_MODE'] = 'only_test'\n",
    "\n",
    "# Finde das trainierte Modell\n",
    "model_dir = Path('./runs/exp/AIR_VIRENet_Colab')\n",
    "\n",
    "if model_dir.exists():\n",
    "    model_files = list(model_dir.glob('*.pth'))\n",
    "    if model_files:\n",
    "        # Verwende das neueste Modell\n",
    "        latest_model = max(model_files, key=os.path.getctime)\n",
    "        test_config['INFERENCE']['MODEL_PATH'] = str(latest_model)\n",
    "        print(f\"‚úì Verwende Modell: {latest_model.name}\")\n",
    "    else:\n",
    "        print(\"‚ö† Keine .pth Modell-Dateien gefunden.\")\n",
    "        print(\"Verf√ºgbare Dateien im Modell-Verzeichnis:\")\n",
    "        !ls -lh {model_dir}\n",
    "else:\n",
    "    print(f\"‚ö† Modell-Verzeichnis nicht gefunden: {model_dir}\")\n",
    "    print(\"Bitte f√ºhre zuerst das Training aus (Zelle 8).\")\n",
    "\n",
    "# Speichere Test-Konfiguration\n",
    "test_config_path = repo_path / 'colab_test_config.yaml'\n",
    "with open(test_config_path, 'w') as f:\n",
    "    yaml.dump(test_config, f, default_flow_style=False)\n",
    "\n",
    "print(f\"\\n‚úì Test-Konfiguration erstellt: {test_config_path}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STARTE TESTING\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "# F√ºhre Testing aus\n",
    "!python main.py --config_file ./colab_test_config.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize-results"
   },
   "source": [
    "## 10. Ergebnisse visualisieren\n",
    "\n",
    "Visualisiere die Trainingsergebnisse und Evaluations-Metriken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-results-code"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Finde Ergebnisdateien\n",
    "results_dir = Path('/content/Infant-Respiration-Estimation/runs/exp')\n",
    "\n",
    "if results_dir.exists():\n",
    "    print(\"Suche nach Ergebnisdateien...\\n\")\n",
    "    \n",
    "    # Suche nach CSV-Dateien\n",
    "    csv_files = list(results_dir.rglob('*.csv'))\n",
    "    \n",
    "    if csv_files:\n",
    "        print(f\"‚úì Gefunden: {len(csv_files)} Ergebnisdateien\\n\")\n",
    "        \n",
    "        for csv_file in csv_files[:5]:  # Zeige bis zu 5 Dateien\n",
    "            print(\"=\"*70)\n",
    "            print(f\"üìä {csv_file.name}\")\n",
    "            print(\"=\"*70)\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_csv(csv_file)\n",
    "                print(df.to_string())\n",
    "                print()\n",
    "                \n",
    "                # Visualisiere numerische Spalten\n",
    "                numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "                if len(numeric_cols) > 0:\n",
    "                    n_cols = min(len(numeric_cols), 4)\n",
    "                    fig, axes = plt.subplots(1, n_cols, figsize=(5*n_cols, 4))\n",
    "                    if n_cols == 1:\n",
    "                        axes = [axes]\n",
    "                    \n",
    "                    for idx, col in enumerate(numeric_cols[:n_cols]):\n",
    "                        axes[idx].plot(df[col], marker='o', linewidth=2, markersize=6)\n",
    "                        axes[idx].set_title(col, fontsize=12, fontweight='bold')\n",
    "                        axes[idx].set_xlabel('Sample/Epoch', fontsize=10)\n",
    "                        axes[idx].set_ylabel('Value', fontsize=10)\n",
    "                        axes[idx].grid(True, alpha=0.3)\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    plt.show()\n",
    "                    \n",
    "                # Statistiken\n",
    "                if len(numeric_cols) > 0:\n",
    "                    print(\"\\nüìà Statistiken:\")\n",
    "                    print(df[numeric_cols].describe())\n",
    "                    print()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† Fehler beim Laden: {e}\\n\")\n",
    "    else:\n",
    "        print(\"‚ö† Keine CSV-Ergebnisdateien gefunden.\")\n",
    "        print(\"\\nVerf√ºgbare Dateien:\")\n",
    "        !find {results_dir} -type f -name \"*\" | head -20\n",
    "else:\n",
    "    print(f\"‚ö† Ergebnisverzeichnis nicht gefunden: {results_dir}\")\n",
    "    print(\"Stelle sicher, dass das Training abgeschlossen wurde.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tensorboard"
   },
   "source": [
    "## 11. TensorBoard (Optional)\n",
    "\n",
    "Visualisiere Training-Logs mit TensorBoard (falls vorhanden)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tensorboard-code"
   },
   "outputs": [],
   "source": [
    "# Lade TensorBoard Extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Starte TensorBoard\n",
    "log_dir = '/content/Infant-Respiration-Estimation/runs/exp'\n",
    "\n",
    "print(f\"Starte TensorBoard...\")\n",
    "print(f\"Log-Verzeichnis: {log_dir}\\n\")\n",
    "\n",
    "%tensorboard --logdir {log_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "save-results"
   },
   "source": [
    "## 12. Ergebnisse sichern (Optional)\n",
    "\n",
    "Speichere wichtige Ergebnisse und Modelle in Google Drive oder lade sie herunter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "save-results-code"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "from google.colab import files\n",
    "\n",
    "results_dir = Path('/content/Infant-Respiration-Estimation/runs/exp')\n",
    "\n",
    "if results_dir.exists():\n",
    "    print(\"Option 1: Ergebnisse herunterladen\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Erstelle ZIP-Archiv\n",
    "    archive_path = Path('/content/training_results')\n",
    "    shutil.make_archive(str(archive_path), 'zip', results_dir)\n",
    "    \n",
    "    zip_file = str(archive_path) + '.zip'\n",
    "    zip_size = Path(zip_file).stat().st_size / 1e6\n",
    "    print(f\"‚úì Archiv erstellt: {zip_file}\")\n",
    "    print(f\"  Gr√∂√üe: {zip_size:.2f} MB\")\n",
    "    \n",
    "    # Uncomment um herunterzuladen\n",
    "    # files.download(zip_file)\n",
    "    # print(\"\\n‚úì Download gestartet!\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Option 2: Nach Google Drive kopieren\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Falls Drive gemountet ist, uncomment die folgenden Zeilen:\")\n",
    "    print()\n",
    "    print(\"# drive_path = Path('/content/drive/MyDrive/InfantRespiration/results')\")\n",
    "    print(\"# drive_path.mkdir(parents=True, exist_ok=True)\")\n",
    "    print(\"# shutil.copytree(results_dir, drive_path / 'exp', dirs_exist_ok=True)\")\n",
    "    print(\"# print(f'‚úì Ergebnisse nach Drive kopiert: {drive_path}')\")\n",
    "    \n",
    "else:\n",
    "    print(f\"‚ö† Keine Ergebnisse gefunden in: {results_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "different-models"
   },
   "source": [
    "## 13. Andere Modelle ausprobieren\n",
    "\n",
    "Experimentiere mit verschiedenen Modellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "different-models-code"
   },
   "outputs": [],
   "source": [
    "# Verf√ºgbare Modelle\n",
    "available_models = {\n",
    "    'VIRENet': {\n",
    "        'description': 'AIRFlowNet - Flow-basiertes Modell (empfohlen f√ºr S√§uglinge)',\n",
    "        'paper': 'https://arxiv.org/pdf/2307.13110.pdf',\n",
    "        'best_for': 'Infant respiration estimation'\n",
    "    },\n",
    "    'DeepPhys': {\n",
    "        'description': 'DeepPhys - Attention-basiertes Modell',\n",
    "        'paper': 'https://arxiv.org/abs/1805.07888',\n",
    "        'best_for': 'General physiological signal estimation'\n",
    "    },\n",
    "    'EfficientPhys': {\n",
    "        'description': 'EfficientPhys - Effizientes Modell',\n",
    "        'paper': 'WACV 2023',\n",
    "        'best_for': 'Fast and accurate cardiac measurement'\n",
    "    },\n",
    "    'Tscan': {\n",
    "        'description': 'TS-CAN - Temporal Shift Attention Network',\n",
    "        'paper': 'NeurIPS 2020',\n",
    "        'best_for': 'On-device contactless vitals measurement'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ü§ñ VERF√úGBARE MODELLE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model_name, info in available_models.items():\n",
    "    print(f\"\\nüì¶ {model_name}\")\n",
    "    print(f\"   {info['description']}\")\n",
    "    print(f\"   Optimal f√ºr: {info['best_for']}\")\n",
    "    print(f\"   Paper: {info['paper']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"\\nüí° Um ein anderes Modell zu verwenden:\")\n",
    "print(\"   1. Gehe zur√ºck zu Zelle 7 (Konfiguration erstellen)\")\n",
    "print(\"   2. √Ñndere config['MODEL']['NAME'] zum gew√ºnschten Modell\")\n",
    "print(\"   3. F√ºhre Zellen 7-8 erneut aus f√ºr Training\")\n",
    "print(\"\\n‚ö° Quick-Test mit anderem Modell:\")\n",
    "\n",
    "# Funktion zum schnellen Modellwechsel\n",
    "def create_config_for_model(model_name):\n",
    "    \"\"\"\n",
    "    Erstelle Config f√ºr spezifisches Modell.\n",
    "    Uncomment und f√ºhre aus um zu testen.\n",
    "    \"\"\"\n",
    "    print(f\"\\nErstelle Konfiguration f√ºr {model_name}...\")\n",
    "    # Code hier...\n",
    "\n",
    "print(\"\\n# Beispiel:\")\n",
    "print(\"# create_config_for_model('DeepPhys')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## 14. Zusammenfassung und n√§chste Schritte\n",
    "\n",
    "### ‚úÖ Was wir getan haben:\n",
    "\n",
    "1. ‚úì GPU √ºberpr√ºft und Colab-Umgebung eingerichtet\n",
    "2. ‚úì Repository geklont\n",
    "3. ‚úì Abh√§ngigkeiten installiert\n",
    "4. ‚úì AIR-125 Dataset heruntergeladen und extrahiert\n",
    "5. ‚úì Konfigurationsdatei erstellt\n",
    "6. ‚úì Modell trainiert (VIRENet)\n",
    "7. ‚úì Modell getestet und evaluiert\n",
    "8. ‚úì Ergebnisse visualisiert\n",
    "\n",
    "### üöÄ N√§chste Schritte:\n",
    "\n",
    "#### Experimente:\n",
    "- **Hyperparameter-Tuning**: Experimentiere mit Learning Rate, Batch Size, Epochs\n",
    "- **Andere Modelle**: Probiere DeepPhys, EfficientPhys oder TS-CAN\n",
    "- **Data Augmentation**: Erweitere das Preprocessing\n",
    "- **COHFACE Dataset**: Evaluiere auf Erwachsenen-Daten\n",
    "\n",
    "#### Optimierung:\n",
    "- **L√§ngeres Training**: Erh√∂he Anzahl der Epochen\n",
    "- **Mixed Precision**: Nutze fp16 f√ºr schnelleres Training\n",
    "- **Gr√∂√üere Batch Size**: Falls GPU-Memory ausreicht\n",
    "\n",
    "#### Deployment:\n",
    "- **Model Export**: Exportiere zu ONNX oder TorchScript\n",
    "- **Inference-Optimierung**: Reduziere Modellgr√∂√üe\n",
    "- **Eigene Videos**: Teste auf eigenen S√§uglingsvideos\n",
    "\n",
    "### üìù Wichtige Konfigurationsparameter:\n",
    "\n",
    "```yaml\n",
    "TRAIN:\n",
    "  BATCH_SIZE: 4          # Erh√∂hen f√ºr schnelleres Training (wenn GPU-Memory erlaubt)\n",
    "  EPOCHS: 10             # Mehr Epochen = bessere Konvergenz\n",
    "  LR: 0.001              # Learning Rate anpassen f√ºr stabileres Training\n",
    "\n",
    "PREPROCESS:\n",
    "  CHUNK_LENGTH: 60       # Video-Chunk-L√§nge in Frames\n",
    "  H: 96                  # Frame-H√∂he (h√∂her = mehr Details, mehr Rechenzeit)\n",
    "  W: 96                  # Frame-Breite\n",
    "  CROP_FACE: False       # Aktivieren f√ºr Gesichtsfokus\n",
    "\n",
    "MODEL:\n",
    "  NAME: VIRENet          # Modellauswahl\n",
    "  DROP_RATE: 0.2         # Dropout f√ºr Regularisierung\n",
    "```\n",
    "\n",
    "### üìö Ressourcen:\n",
    "\n",
    "- **Paper**: [Automatic Infant Respiration Estimation from Video](https://arxiv.org/pdf/2307.13110.pdf)\n",
    "- **GitHub**: [Infant-Respiration-Estimation](https://github.com/J0R0W/Infant-Respiration-Estimation)\n",
    "- **Original rPPG-Toolbox**: [ubicomplab/rPPG-Toolbox](https://github.com/ubicomplab/rPPG-Toolbox)\n",
    "- **Dataset**: [AIR-125](https://coe.northeastern.edu/Research/AClab/AIR-125/)\n",
    "\n",
    "### üíæ Datensicherung:\n",
    "\n",
    "**WICHTIG**: Colab-Sessions sind tempor√§r!\n",
    "\n",
    "- Speichere wichtige Ergebnisse in Google Drive\n",
    "- Lade trainierte Modelle herunter\n",
    "- Exportiere Evaluations-Metriken\n",
    "\n",
    "### üêõ Troubleshooting:\n",
    "\n",
    "**Problem: CUDA out of memory**\n",
    "- L√∂sung: Reduziere `BATCH_SIZE` in der Config\n",
    "\n",
    "**Problem: Session Timeout**\n",
    "- L√∂sung: Aktiviere Google Drive f√ºr Persistenz, nutze Colab Pro\n",
    "\n",
    "**Problem: Dataset Download fehlgeschlagen**\n",
    "- L√∂sung: Pr√ºfe Internetverbindung, versuche erneut\n",
    "\n",
    "**Problem: Import Errors**\n",
    "- L√∂sung: F√ºhre Zelle 4 (Installation) erneut aus\n",
    "\n",
    "### üìß Support:\n",
    "\n",
    "Bei Fragen oder Problemen:\n",
    "- Siehe README.md im Repository\n",
    "- √ñffne ein Issue auf GitHub\n",
    "- Konsultiere das Original-Paper\n",
    "\n",
    "---\n",
    "\n",
    "**Viel Erfolg mit deinen Experimenten! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AIR_Complete_Pipeline_Colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
